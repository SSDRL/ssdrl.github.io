<!DOCTYPE html>
<html lang="en">

  <head>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
    <meta name="viewport" content="width=1024">

    <title>VLMNM Workshop @ ICRA 2024</title>

    <!-- <link rel="icon" type="image/png" href="images/robot_emoji.png"> -->

    <!-- bootstrap -->
    <link rel="stylesheet" href="./files/bootstrap.min.css">
    <link rel="stylesheet" href="./files/bootstrap-theme.min.css">
    <link rel="stylesheet" type="text/css" href="./files/style.css">

    <!-- Google fonts -->
    <link href="./files/google-fonts.css" rel="stylesheet" type="text/css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-47054450-13"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-47054450-13');
    </script>

  </head>


  <body>

    <div class="container-fluid">

      <div class="row section">
        <div class="text-center">
          <h1 style="color:#443535">Vision-Language Models for Navigation and Manipulation</h1>
          <br>
          <h4>Full-day hybrid workshop at <a href="https://2024.ieee-icra.org/">ICRA 2024</a></h4>
          <h4> </h4>
          <h4>Either on May 13 or May 17, 2024, <a href="https://greenwichmeantime.com/time/japan/" target="_blank">Japan Standard Time (JST)</a>, Yokohama (Japan)</h4>
          <hr>
        </div>
      </div>

      </div>

      <div class="row section">
        <center><h3>Introduction</h3><hr></center>

        With the rising capabilities of LLMs and VLMs, the past two years have seen a surge in research work using VLMs for navigation and manipulation.
        Fusing the capabilities of visual interpretation with natural language processing, these models are poised to redefine how robotic systems interact
        with both their environment and human counterparts. The relevance of this topic cannot be overstated; as the frontier of human-robot interaction expands,
        so does the necessity for robots to comprehend and operate within complex environments using naturalistic instructions. Our workshop will not only reflect
        the state-of-the-art advancements in this domain, by featuring a diverse set of speakers, from senior academics to researchers in early careers, from industry
        researchers to companies producing mobile manipulation platforms, from researchers who are enthusiastic about using VLMs for robotics to those who have
        reservations about it. We aim for this event to be a catalyst for originality and diversity at ICRA 2024. We believe that, amidst a sea of workshops, ours
        will provide unique perspectives that will push the boundaries of what's achievable in robot navigation and manipulation.
        <br><br>
        In this workshop, we plan to discuss:
        <ul>
          <li>How can VLMs/LLMs enhance robotics navigation and manipulation?</li>
          <li>How to extract world knowledge from pre-trained VLMs/LLMs and apply them to navigation and manipulation?</li>
          <li>How to integrate VLMs/LLMs with robot components, such as perception, control, and planning? How to account for partial observability and uncertainty?</li>
          <li>Benchmarks and datasets to assess the generalization capabilities of VLMs/LLMs for navigation and manipulation.</li>
          <li>Capabilities and limitations of VLMs/LLMs for navigation and manipulation (e.g. in task planning, spatial understanding)</li>
          <li>New interaction modes between robots and humans enabled by VLMs/LLMs.</li>
        </ul>

      </div>

      <div class="row section">
        <center><h3>Call for Papers</h3><hr></center>
          We invite submissions including but not limited to the following topics:
          <ul>
            <li>Applications:</li>
            <ul>
              <li>Integration of VLM/LLMs for manipulation and navigation</li>
              <li>VLM/LLMs for perception/scene understanding/state estimation</li>
              <li>VLM/LLMs for control/skill learning/motion generation</li>
              <li>VLM/LLMs for decision-making/reasoning/planning</li>
              <li>VLM/LLMs as world models</li>
              <li>VLMs/LLMs for multimodal task specifications</li>
              <li>VLMs/LLMs for human-robot/robot-robot interactions</li>
              <li>VLMs/LLMs for scene and task generation</li>
            </ul>
            <li>New Capabilities:</li>
            <ul>
              <li>Open-vocabulary perception/navigation/manipulation</li>
              <li>Commonsense reasoning with VLM/LLMs</li>
              <li>Generalization to unseen object categories, environments, and tasks</li>
              <li>Bootstrapping learning from scarce data</li>
              <li>Natural language interaction with everyday users</li>
            </ul>
            <li>Datasets/Benchmarks:</li>
            <ul>
              <li>Internet-scale data for training robotics foundation models</li>
              <li>Mobile manipulation benchmarks for VLM/LLM-based systems</li>
            </ul>
            <li>Limitations:</li>
            <ul>
              <li>Failure modes of VLM/LLMs</li>
              <li>Robustness of VLM/LLMs</li>
              <li>Certifiabilities of VLM/LLMs</li>
            </ul>
          </ul>
          
          Submissions should have up to 4 pages of technical content, with no limit on references/appendices. Submissions are suggested to follow the ICRA double-column format with the template available <a href="https://ras.papercept.net/conferences/support/support.php" target="_blank">here</a>. 
          We encourage authors to upload videos, code, or data as supplementary material (due on the same day as the paper). Following the main conference, our workshop will use a <b>single-blind</b> review process. 
          We welcome both unpublished, original contributions and recently published relevant works.
          
          Accepted papers will be presented as posters or orals and made public via the workshop’s OpenReview page with the authors’ consent. 
          We strongly encourage at least one of the authors to <b>present on-site</b> during the workshop. Our workshop will feature a Best Paper Award. <br>
          
          Important Dates:
          <ul>
            <li>Submission portal opens: January 29, 2024</li>
            <li>Paper submission deadline: March 11, Monday, 2024 (AoE)</li>
            <li>Notification of acceptance: March 27, 2024</li>
            <li>Camera-Ready deadline: April 26, 2024</li>
            <li>Workshop @ ICRA 2024: May 13 or 17, 2024 (exact date will be updated when the conference finalizes the schedule)</li>
          </ul>
          
          Submissions will be accepted through OpenReview. Submissions will not be public during the review process. Only accepted papers will be made public.

      </div>

    

      <div class="row section">
        <center><h3>Tentative Schedule</h3><hr></center>
        <div class="text-justify">
          <table>
            <thead>
              <tr>
                <th class="time">Time (<a href="https://greenwichmeantime.com/time/japan/" target="_blank">JST</a>)</th>
                <th class="event">Event</th>
                <th class="description">Description</th>
                <th class="time">Time (<a href="https://greenwichmeantime.com/time-zone/usa/pacific-daylight-time/" target="_blank">PDT</a>) <br>(1 Day Earlier)</th>
              </tr>
            </thead>

            <tbody>
              <tr class="highlight">
                <td class="time">8:30 - 8:50</td>
                <td class="event">Coffee and Pasteries</td>
                <td class="description">
                    <b></b>
                </td>
                <td class="time">15:30 - 15:50</td>
              </tr>

              <tr>
                <td class="time">8:50 - 9:00</td>
                <td class="event">
                  Introduction
                </td>
                <td class="description">
                  <b>by the Organizing Committee</b>
                </td>
                <td class="time">15:50 - 16:00</td>
              </tr>

              <tr class="highlight">
                <td class="time">9:00 - 9:20</td>
                <td class="event">
                  LLM-State: Adaptive State Representation for Long-Horizon Task Planning in the Open World
                </td>
                <td class="description">
                  <a href="https://www.comp.nus.edu.sg/~dyhsu/" target="_blank"><img src="photos/Speakers/DavidHsu.jpeg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://www.comp.nus.edu.sg/~dyhsu/" target="_blank">Prof. David Hsu</a>
                  <br>
                  National University of Singapore
                </td>
                <td class="time">16:00 - 16:20</td>
              </tr>

              <tr>
                <td class="time">9:20 - 9:40</td>
                <td class="event">
                  Limitations of using LLM for Planning
                </td>
                <td class="description">
                  <a href="https://search.asu.edu/profile/95646" target="_blank"><img src="photos/Speakers/SubbaraoKambhampati.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://search.asu.edu/profile/95646" target="_blank">Prof. Subbarao Kambhampati</a>
                  <br>
                  Arizona State University
                </td>
                <td class="time">16:20 - 16:40</td>
              </tr>

              <tr class="highlight">
                <td class="time">9:40 - 10:00</td>
                <td class="event">
                  LLM + Formal Planner
                </td>
                <td class="description">
                  <a href="https://chuchu.mit.edu/" target="_blank"><img src="photos/Speakers/ChuchuFan.jpeg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://chuchu.mit.edu/" target="_blank">Prof. Chuchu Fan</a>
                  <br>
                  Massachusetts Institute of Technology
                </td>
                <td class="time">16:40 - 17:00</td>
              </tr>

              <tr>
                <td class="time">10:00 - 10:30</td>
                <td class="event">
                  Panel 1
                </td>
                <td class="description">
                  <b>Panelists:</b>
                  <br><a href="https://www.comp.nus.edu.sg/~dyhsu/" target="_blank">Prof. David Hsu</a>
                  <br><a href="https://search.asu.edu/profile/95646" target="_blank">Prof. Subbarao Kambhampati</a>
                  <br><a href="https://chuchu.mit.edu/" target="_blank">Prof. Chuchu Fan</a>
                </td>
                <td class="time">17:00 - 17:30</td>
              </tr>

              <tr class="highlight">
                <td class="time">10:30 - 11:00</td>
                <td class="event">
                  Coffee Break and Poster Session
                </td>
                <td class="description">
                  <b>30 Mins</b>
                </td>
                <td class="time">17:30 - 18:00</td>
              </tr>

              <tr>
                <td class="time">11:00 - 11:20</td>
                <td class="event">
                  LLM for Mobile Manipulation
                </td>
                <td class="description">
                  <a href="https://www.cs.utexas.edu/~yukez/" target="_blank"><img src="photos/Speakers/YukeZhu.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://www.cs.utexas.edu/~yukez/" target="_blank">Prof. Yuke Zhu</a>
                  <br>
                  University of Texas at Austin
                </td>
                <td class="time">18:00 - 18:20</td>
              </tr>

              <tr class="highlight">
                <td class="time">11:20 - 11:40</td>
                <td class="event">
                  Mobile Manipulation, Multi-Agent Coordination, Long Horizon Tasks
                </td>
                <td class="description">
                  <a href="https://web.stanford.edu/~bohg/" target="_blank"><img src="photos/Speakers/JeannetteBohg.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://web.stanford.edu/~bohg/" target="_blank">Prof. Jeannette Bohg</a>
                  <br>
                  Stanford University
                </td>
                <td class="time">18:20 - 18:40</td>
              </tr>

              <tr>
                <td class="time">11:40 - 12:00</td>
                <td class="event">
                  Mobile Manipulation
                </td>
                <td class="description">
                  <a href="https://robertomartinmartin.com/" target="_blank"><img src="photos/Speakers/RobertoMartinMartin.jpeg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://robertomartinmartin.com/" target="_blank">Prof. Roberto Martín-Martín</a>
                  <br>
                  University of Texas at Austin
                </td>
                <td class="time">18:40 - 19:00</td>
              </tr>

              <tr class="highlight">
                <td class="time">12:00 - 12:30</td>
                <td class="event">
                  Panel 2
                </td>
                <td class="description">
                  <b>Panelists:</b>
                  <br><a href="https://www.cs.utexas.edu/~yukez/" target="_blank">Prof. Yuke Zhu</a>
                  <br><a href="https://web.stanford.edu/~bohg/" target="_blank">Prof. Jeanette Bohg</a>
                  <br><a href="https://robertomartinmartin.com/" target="_blank">Prof. Roberto Martín-Martín</a>
                </td>
                <td class="time">19:00 - 19:30</td>
              </tr>

              <tr>
                <td class="time">12:30 - 14:00</td>
                <td class="event">
                  Lunch Break
                </td>
                <td class="description">
                  <b>90 Mins</b>
                </td>
                <td class="time">19:30 - 21:00</td>
              </tr>

              <tr class="highlight">
                <td class="time">14:00 - 14:40</td>
                <td class="event">
                  Panel 3 with Industry Speakers
                </td>
                <td class="description">
                  <b>Panelists:</b>
                  <br><a href="https://charliekemp.com/" target="_blank"><img src="photos/Speakers/CharlieKemp.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><a href="https://charliekemp.com/" target="_blank">Prof. Charlie Kemp</a>
                  <br>
                  <a href="https://hello-robot.com/" target="_blank">Hello Robot</a>

                  <br><a href="https://www.pfrobotics.jp/" target="_blank"><img src="photos/Speakers/TakafumiWatanabe.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><a href="https://www.pfrobotics.jp/" target="_blank">Takafumi Watanabe</a>
                  <br>
                  <a href="https://www.preferred.jp/en/projects/personal-robot/" target="_blank">Preferred Networks Robotics</a>

                  <br><a href="https://mohitshridhar.com/" target="_blank"><img src="photos/Speakers/MohitShridhar.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><a href="https://mohitshridhar.com/" target="_blank">Dr. Mohit Shridhar</a>
                  <br>
                  <a href="https://www.youtube.com/watch?v=JYFYLKEinlk&ab_channel=Dyson" target="_blank">Dyson Robot Learning Lab</a>
                </td>
                <td class="time">21:00 - 21:40</td>
              </tr>

              <tr>
                <td class="time">14:40 - 15:00</td>
                <td class="event">
                  Spotlight Talks
                </td>
                <td class="description">
                  <b>4 Talks of 5 mins each</b>
                </td>
                <td class="time">21:40 - 22:00</td>
              </tr>

              <tr class="highlight">
                <td class="time">15:00 - 15:30</td>
                <td class="event">
                  Coffee Break and Poster Session
                </td>
                <td class="description">
                  <b>30 Mins</b>
                </td>
                <td class="time">22:00 - 22:30</td>
              </tr>

              <tr>
                <td class="time">15:30 - 15:50</td>
                <td class="event">
                  LLM and VLM for Manipulation
                </td>
                <td class="description">
                  <a href="https://andyzeng.github.io/" target="_blank"><img src="photos/Speakers/AndyZeng.jpeg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://andyzeng.github.io/" target="_blank">Dr. Andy Zeng</a>
                  <br>
                  Google DeepMind
                </td>
                <td class="time">22:30 - 22:50</td>
              </tr>

              <tr class="highlight">
                <td class="time">15:50 - 16:10</td>
                <td class="event">
                  Foundation Models of and for Navigation
                </td>
                <td class="description">
                  <a href="https://people.eecs.berkeley.edu/~shah/" target="_blank"><img src="photos/Speakers/DhruvShah.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://people.eecs.berkeley.edu/~shah/" target="_blank">Dhruv Shah</a>
                  <br>
                  University of California, Berkeley
                </td>
                <td class="time">22:50 - 23:10</td>
              </tr>

              <tr>
                <td class="time">16:10 - 16:30</td>
                <td class="event">
                  VLM for Mobile Manipulation / ProgPrompt 2
                </td>
                <td class="description">
                  <a href="https://homes.cs.washington.edu/~fox/" target="_blank"><img src="photos/Speakers/DieterFox.jpeg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://homes.cs.washington.edu/~fox/" target="_blank">Prof. Dieter Fox</a> (Tentative)
                  <br>
                  University of Washington / NVIDIA
                </td>
                <td class="time">23:10 - 23:30</td>
              </tr>

              <tr class="highlight">
                <td class="time">16:30 - 16:50</td>
                <td class="event">
                  BEHAVIOR Benchmark
                </td>
                <td class="description">
                  <a href="https://ai.stanford.edu/~zharu/" target="_blank"><img src="photos/Speakers/RuohanZhang.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  <br><br>
                  <a href="https://ai.stanford.edu/~zharu/" target="_blank">Dr. Ruohan Zhang</a>
                  <br>
                  Ruohan Zhang
                </td>
                <td class="time">23:30 - 23:50</td>
              </tr>

              <tr>
                <td class="time">16:50 - 17:20</td>
                <td class="event">
                  Panel Discussion 4
                </td>
                <td class="description">
                  <b>Panelists:</b>
                  <br><a href="https://andyzeng.github.io/" target="_blank">Dr. Andy Zeng</a>
                  <br><a href="https://people.eecs.berkeley.edu/~shah/" target="_blank">Dhruv Shah</a>
                  <br><a href="https://homes.cs.washington.edu/~fox/" target="_blank">Prof. Dieter Fox</a> (Tentative)
                  <br><a href="https://ai.stanford.edu/~zharu/" target="_blank">Dr. Ruohan Zhang</a>
                </td>
                <td class="time">23:50 - 00:20</td>
              </tr>

              <tr class="highlight">
                <td class="time">17:20 - 17:50</td>
                <td class="event">
                  Moderated Open Discussion
                </td>
                <td class="description">
                  <b>All in-person attendees</b>
                </td>
                <td class="time">00:20 - 00:50</td>
              </tr>

              <tr>
                <td class="time">17:50 - 18:00</td>
                <td class="event">
                  Awards Ceremony and Closing Remarks
                </td>
                <td class="description">
                  <b></b>
                </td>
                <td class="time">00:50 - 01:00</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>

      <div class="row section">
        <center><h3>Organizers</h3><hr></center>

        <table>
          <tbody>
            <tr>
              <td width="25%" class="organizer">
                <a href="https://cpaxton.github.io/about/" target="_blank"><img src="photos/Organizers/ChrisPaxton.jpeg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="https://cpaxton.github.io/about/" target="_blank">Chris Paxton</a>
                <br>
                FAIR, Meta
              </td>

              <td width="25%" class="organizer">
                <a href="https://fxia22.github.io/" target="_blank"><img src="photos/Organizers/FeiXia.jpeg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="https://fxia22.github.io/" target="_blank">Fei Xia</a>
                <br>
                Google Deepmind
              </td>

              <td width="25%" class="organizer">
                <a href="http://karmeshyadav.com/" target="_blank"><img src="photos/Organizers/KarmeshYadav.jpeg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="http://karmeshyadav.com/" target="_blank">Karmesh Yadav</a>
                <br>
                Georgia Tech
              </td>

              <td width="25%" class="organizer">
                <a href="https://mahis.life/" target="_blank"><img src="photos/Organizers/MahiShafiullah.jpeg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="https://mahis.life/" target="_blank">Nur Muhammad Mahi Shafiullah</a>
                <br>
                New York University
              </td>
            </tr>

            <tr>
              <td width="25%" class="organizer">
                <a href="https://www.microsoft.com/en-us/research/people/nawake/" target="_blank"><img src="photos/Organizers/NaokiWake.jpeg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="https://www.microsoft.com/en-us/research/people/nawake/" target="_blank">Naoki Wake</a>
                <br>
                Microsoft Research
              </td>

              <td width="25%" class="organizer">
                <a href="http://weiyuliu.com/" target="_blank"><img src="photos/Organizers/WeiyuLiu.jpg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="http://weiyuliu.com/" target="_blank">Weiyu Liu</a>
                <br>
                Stanford University
              </td>

              <td width="25%" class="organizer">
                <a href="https://research.google/people/107814/" target="_blank"><img src="photos/Organizers/YujinTang.jpeg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="https://research.google/people/107814/" target="_blank">Yujin Tang</a>
                <br>
                Google DeepMind Tokyo
              </td>

              <td width="25%" class="organizer">
                <a href="https://zt-yang.com/ " target="_blank"><img src="photos/Organizers/ZhutianYang.jpg" width="150px" align="bottom" style="border-radius: 50%"></a>
                <br><br>
                <a href="https://zt-yang.com/ " target="_blank">Zhutian Yang</a>
                <br>
                MIT, NVIDIA Research
              </td>

            </tr>
          </tbody>
        </table>
      </div>

      <div class="row section">
        <center><h3>Contact</h3><hr></center>
        For further information or questions, please contact us at <b>vlm-navigation-manipulation-workshop [AT] gmail [DOT] com</b>

    </div>

  </body>

</html>
